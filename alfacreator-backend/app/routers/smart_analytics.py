# alfacreator-backend/app/routers/smart_analytics_router.py

import io
import json
import pandas as pd
import httpx
from fastapi import (
    APIRouter, UploadFile, Form, HTTPException, Query, File, Depends
)
from fastapi.responses import JSONResponse
from fastapi import Depends
from sqlalchemy.ext.asyncio import AsyncSession
from typing import Optional

# --- –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã ---
from app.services import social_parser  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å —Ü–µ–ª–∏–∫–æ–º
from app.schemas.socialmedia import SocialMediaInfo
from app.core.llm_client import llm_client
from app.database import get_db
from app import crud
from app.core.dependencies import get_db, get_current_user
from app.schemas.user import User as UserSchema
from app.schemas import history as history_schema


router = APIRouter()


@router.get("/analyze/social", response_model=SocialMediaInfo)
async def get_social_analysis(link: str = Query(..., description="–°—Å—ã–ª–∫–∞ –Ω–∞ —Å–æ—Ü—Å–µ—Ç—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")):
    analysis_result = await social_parser.analyze_social(link)
    if not analysis_result:
        raise HTTPException(
            status_code=400,
            detail="–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Å—Å—ã–ª–∫—É –∏–ª–∏ —Å–æ—Ü—Å–µ—Ç—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è."
        )
    return analysis_result


@router.post("/smart")
async def analyze_business(
        db: AsyncSession = Depends(get_db),
        file: Optional[UploadFile] = File(None),
        link: Optional[str] = Form(None),
        current_user: UserSchema = Depends(get_current_user)
):
    if not file and not link:
        raise HTTPException(status_code=400, detail="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å —Ñ–∞–π–ª –∏–ª–∏ —Å—Å—ã–ª–∫—É.")

    # --- –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê –ü–†–û–í–ï–†–ö–ò ---
    user_data_summary = None
    if file:
        contents = await file.read()
        try:
            df = pd.read_csv(io.BytesIO(contents)) if file.filename.endswith(".csv") else pd.read_excel(
                io.BytesIO(contents))
            user_data_summary = summarize_client_data(df)
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")

    social_data_summary = None
    if link:
        social_info = await social_parser.analyze_social(link)
        if social_info:
            social_data_summary = social_info.analysis_summary

    # "–û–•–†–ê–ù–ù–ò–ö": –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞, –Ω–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–π —Å—Å—ã–ª–∫–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
    if not user_data_summary and not social_data_summary:
        raise HTTPException(
            status_code=400,
            detail="–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ —Å–æ—Ü—Å–µ—Ç—å –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–∞–π–ª."
        )
    # ------------------------------

    try:
        trends = await get_latest_trends()

        prompt = f"""
        –¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π SMM-—Å—Ç—Ä–∞—Ç–µ–≥ –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –º–∞–ª–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞.
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç-–ø–ª–∞–Ω –Ω–∞ 7 –¥–Ω–µ–π.
        –¢–≤–æ–π –æ—Ç–≤–µ—Ç –î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ü–û–õ–ù–û–°–¢–¨–Æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –≤–∫–ª—é—á–∞—è –∫–ª—é—á–∏ –≤ JSON.

        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–∏–∑–Ω–µ—Å–µ –∫–ª–∏–µ–Ω—Ç–∞:
        üìä –ö–ª–∏–µ–Ω—Ç—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ:
        {user_data_summary or "–ù–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã."}

        üåê –ê–Ω–∞–ª–∏–∑ —Å–æ—Ü—Å–µ—Ç–µ–π ({link or "–ù–µ —É–∫–∞–∑–∞–Ω–∞"}):
        {social_data_summary or "–ù–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –∏–ª–∏ —Å—Å—ã–ª–∫–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞."}

        üî• –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã –≤ –†–æ—Å—Å–∏–∏:
        {trends}

        –û—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –≤—ã–ø–æ–ª–Ω–∏ –¥–≤–∞ —à–∞–≥–∞:
        1. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π 2-3 –∫–ª—é—á–µ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è.
        2. –°–æ—Å—Ç–∞–≤—å –ø–æ—à–∞–≥–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç-–ø–ª–∞–Ω –Ω–∞ –Ω–µ–¥–µ–ª—é.

        –í–ê–ñ–ù–û: –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –°–¢–†–û–ì–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ –≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –í–æ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:
        {{
        "kratkieRekomendatsii": [
            "–ö—Ä–∞—Ç–∫–∞—è –∫–ª—é—á–µ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è ‚Ññ1...",
            "–ö—Ä–∞—Ç–∫–∞—è –∫–ª—é—á–µ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è ‚Ññ2..."
        ],
        "celNaNedelyu": "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –∑–¥–µ—Å—å –≥–ª–∞–≤–Ω—É—é —Ü–µ–ª—å –Ω–∞ –Ω–µ–¥–µ–ª—é ",
        "kontentPlan": [
            {{
            "den": "–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫",
            "tema": "–¢–µ–º–∞ –¥–Ω—è ",
            "ideyaPosta": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –∏–¥–µ—è –¥–ª—è –ø–æ—Å—Ç–∞ ",
            "format": "Reels",
            "prizyvKDeystviyu": "–ü—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é "
            }}
        ]
        }}
        """

        result_str = await llm_client.generate_json_response(prompt)
        result_data = json.loads(result_str)

        # 1. –§–æ—Ä–º–∏—Ä—É–µ–º Pydantic-–æ–±—ä–µ–∫—Ç HistoryCreate
        input_data_for_history = {"link": link, "filename": file.filename if file else None}
        history_entry_data = history_schema.HistoryCreate(
            request_type="smart_analytics",
            input_data=input_data_for_history,
            output_data=result_data
        )

        await crud.create_history_entry(
            db=db,
            request_type="smart_analytics",
            user_id=current_user.id,
            entry=history_entry_data
        )

        return JSONResponse(content=result_data)

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def summarize_client_data(df: pd.DataFrame) -> str:
    """
    –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –∞–Ω–∞–ª–∏–∑ CSV/Excel ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π, —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è.
    """
    try:
        info = f"–ù–∞–π–¥–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫. –ö–æ–ª–æ–Ω–∫–∏: {', '.join(df.columns)}."
        if "amount" in df.columns and pd.api.types.is_numeric_dtype(df["amount"]):
            avg_amount = df["amount"].mean()
            info += f" –°—Ä–µ–¥–Ω–∏–π —á–µ–∫: {avg_amount:.2f}."
        return info
    except Exception:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–∞."


async def get_latest_trends() -> str:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤ (–ø–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞, –Ω–æ –º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π API).
    """
    try:
        async with httpx.AsyncClient() as client:
            res = await client.get("https://trends.google.com/trending/rss?geo=RU")
            if res.status_code == 200:
                return "Google Trends: –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–µ–º—ã –Ω–µ–¥–µ–ª–∏."
    except:
        pass
    return "–¢—Ä–µ–Ω–¥—ã –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å."
